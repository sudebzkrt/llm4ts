# data_provider/data_loader.py (TAM VE DÜZELTİLMİŞ HALİ)

import os
import numpy as np
import pandas as pd
import glob
import re
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from utils.timefeatures import time_features
import warnings
import argparse
from pathlib import Path # <<< Hata çözümü için bu import gerekli

warnings.filterwarnings("ignore")

# Orijinal sınıflarınız burada olduğu gibi kalıyor...
class Dataset_ETT_hour(Dataset):
    def __init__(
        self,
        root_path,
        flag="train",
        size=None,
        features="S",
        data_path="ETTh1.csv",
        target="OT",
        scale=True,
        timeenc=0,
        freq="h",
        seasonal_patterns=None,
        percent=100,
        return_single_feature=False,
    ):
        if size == None:
            self.seq_len = 24 * 4 * 4
            self.label_len = 24 * 4
            self.pred_len = 24 * 4
        else:
            self.seq_len = size[0]
            self.label_len = size[1]
            self.pred_len = size[2]
        assert flag in ["train", "test", "val"]
        type_map = {"train": 0, "val": 1, "test": 2}
        self.set_type = type_map[flag]

        self.features = features
        self.target = target
        self.scale = scale
        self.timeenc = timeenc
        self.freq = freq

        self.percent = percent
        self.return_single_feature = return_single_feature
        self.root_path = root_path
        self.data_path = data_path
        self.__read_data__()
        self.C = self.data_x.shape[1]

    def __read_data__(self):
        self.scaler = StandardScaler()
        # >>> DÜZELTME: str() ekleyerek Path nesnesinin metne çevrilmesini garantiledim.
        df_raw = pd.read_csv(str(Path(self.root_path) / self.data_path))

        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]
        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]
        border1 = border1s[self.set_type]
        border2 = border2s[self.set_type]

        if self.set_type == 0:
            border2 = (border2 - self.seq_len) * self.percent // 100 + self.seq_len

        if self.features == "M" or self.features == "MS":
            cols_data = df_raw.columns[1:]
            df_data = df_raw[cols_data]
        elif self.features == "S":
            df_data = df_raw[[self.target]]

        if self.scale:
            train_data = df_data[border1s[0] : border2s[0]]
            self.scaler.fit(train_data.values)
            data = self.scaler.transform(df_data.values)
        else:
            data = df_data.values

        df_stamp = df_raw[["date"]][border1:border2]
        df_stamp["date"] = pd.to_datetime(df_stamp.date)
        if self.timeenc == 0:
            df_stamp["month"] = df_stamp.date.apply(lambda row: row.month, 1)
            df_stamp["day"] = df_stamp.date.apply(lambda row: row.day, 1)
            df_stamp["weekday"] = df_stamp.date.apply(lambda row: row.weekday(), 1)
            df_stamp["hour"] = df_stamp.date.apply(lambda row: row.hour, 1)
            data_stamp = df_stamp.drop(["date"], 1).values
        elif self.timeenc == 1:
            data_stamp = time_features(pd.to_datetime(df_stamp["date"].values), freq=self.freq)
            data_stamp = data_stamp.transpose(1, 0)

        self.data_x = data[border1:border2]
        self.data_y = data[border1:border2]
        self.data_stamp = data_stamp

    def __getitem__(self, index):
        if self.return_single_feature == False:
            s_begin = index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end]
            seq_y = self.data_y[r_begin:r_end]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        else:
            original_index = index // self.C
            channel_index = index % self.C
            s_begin = original_index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end, channel_index : channel_index + 1]
            seq_y = self.data_y[r_begin:r_end, channel_index : channel_index + 1]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        return seq_x, seq_y, seq_x_mark, seq_y_mark

    def __len__(self):
        if self.return_single_feature == False:
            return len(self.data_x) - self.seq_len - self.pred_len + 1
        else:
            return (len(self.data_x) - self.seq_len - self.pred_len + 1) * self.C

    def inverse_transform(self, data):
        return self.scaler.inverse_transform(data)


class Dataset_ETT_minute(Dataset):
    def __init__(
        self, root_path, flag="train", size=None, features="S",
        data_path="ETTm1.csv", target="OT", scale=True, timeenc=0, freq="t",
        seasonal_patterns=None, percent=100, return_single_feature=False,
    ):
        if size == None:
            self.seq_len = 24 * 4 * 4
            self.label_len = 24 * 4
            self.pred_len = 24 * 4
        else:
            self.seq_len = size[0]
            self.label_len = size[1]
            self.pred_len = size[2]
        assert flag in ["train", "test", "val"]
        type_map = {"train": 0, "val": 1, "test": 2}
        self.set_type = type_map[flag]

        self.features = features
        self.target = target
        self.scale = scale
        self.timeenc = timeenc
        self.freq = freq
        self.percent = percent
        self.return_single_feature = return_single_feature
        self.root_path = root_path
        self.data_path = data_path
        self.__read_data__()
        self.C = self.data_x.shape[1]

    def __read_data__(self):
        self.scaler = StandardScaler()
        df_raw = pd.read_csv(str(Path(self.root_path) / self.data_path))
        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4 + 4*30*24*4 - self.seq_len]
        border2s = [12*30*24*4, 12*30*24*4 + 4*30*24*4, 12*30*24*4 + 8*30*24*4]
        border1 = border1s[self.set_type]
        border2 = border2s[self.set_type]
        if self.set_type == 0:
            border2 = (border2 - self.seq_len) * self.percent // 100 + self.seq_len
        if self.features == "M" or self.features == "MS":
            cols_data = df_raw.columns[1:]
            df_data = df_raw[cols_data]
        elif self.features == "S":
            df_data = df_raw[[self.target]]
        if self.scale:
            train_data = df_data[border1s[0] : border2s[0]]
            self.scaler.fit(train_data.values)
            data = self.scaler.transform(df_data.values)
        else:
            data = df_data.values
        df_stamp = df_raw[["date"]][border1:border2]
        df_stamp["date"] = pd.to_datetime(df_stamp.date)
        if self.timeenc == 0:
            df_stamp["month"] = df_stamp.date.apply(lambda row: row.month, 1)
            df_stamp["day"] = df_stamp.date.apply(lambda row: row.day, 1)
            df_stamp["weekday"] = df_stamp.date.apply(lambda row: row.weekday(), 1)
            df_stamp["hour"] = df_stamp.date.apply(lambda row: row.hour, 1)
            df_stamp["minute"] = df_stamp.date.apply(lambda row: row.minute, 1)
            df_stamp["minute"] = df_stamp.minute.map(lambda x: x // 15)
            data_stamp = df_stamp.drop(["date"], 1).values
        elif self.timeenc == 1:
            data_stamp = time_features(pd.to_datetime(df_stamp["date"].values), freq=self.freq)
            data_stamp = data_stamp.transpose(1, 0)
        self.data_x = data[border1:border2]
        self.data_y = data[border1:border2]
        self.data_stamp = data_stamp

    def __getitem__(self, index):
        if self.return_single_feature == False:
            s_begin = index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end]
            seq_y = self.data_y[r_begin:r_end]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        else:
            original_index = index // self.C
            channel_index = index % self.C
            s_begin = original_index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end, channel_index : channel_index + 1]
            seq_y = self.data_y[r_begin:r_end, channel_index : channel_index + 1]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        return seq_x, seq_y, seq_x_mark, seq_y_mark

    def __len__(self):
        if self.return_single_feature == False:
            return len(self.data_x) - self.seq_len - self.pred_len + 1
        else:
            return (len(self.data_x) - self.seq_len - self.pred_len + 1) * self.C

    def inverse_transform(self, data):
        return self.scaler.inverse_transform(data)


class Dataset_Custom(Dataset):
    def __init__(self, root_path, flag="train", size=None, features="S",
        data_path="ETTh1.csv", target="OT", scale=True, timeenc=0, freq="h",
        seasonal_patterns=None, percent=100, return_single_feature=False,
    ):
        if size == None:
            self.seq_len = 24 * 4 * 4
            self.label_len = 24 * 4
            self.pred_len = 24 * 4
        else:
            self.seq_len = size[0]
            self.label_len = size[1]
            self.pred_len = size[2]
        assert flag in ["train", "test", "val"]
        type_map = {"train": 0, "val": 1, "test": 2}
        self.set_type = type_map[flag]

        self.features = features
        self.target = target
        self.scale = scale
        self.timeenc = timeenc
        self.freq = freq
        self.percent = percent
        self.return_single_feature = return_single_feature
        self.root_path = root_path
        self.data_path = data_path
        self.__read_data__()
        self.C = self.data_x.shape[1]

    def __read_data__(self):
        self.scaler = StandardScaler()
        df_raw = pd.read_csv(str(Path(self.root_path) / self.data_path))
        cols = list(df_raw.columns)
        cols.remove(self.target)
        cols.remove("date")
        df_raw = df_raw[["date"] + cols + [self.target]]
        num_train = int(len(df_raw) * 0.7)
        num_test = int(len(df_raw) * 0.2)
        num_vali = len(df_raw) - num_train - num_test
        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]
        border2s = [num_train, num_train + num_vali, len(df_raw)]
        border1 = border1s[self.set_type]
        border2 = border2s[self.set_type]
        if self.set_type == 0:
            border2 = (border2 - self.seq_len) * self.percent // 100 + self.seq_len
        if self.features == "M" or self.features == "MS":
            cols_data = df_raw.columns[1:]
            df_data = df_raw[cols_data]
        elif self.features == "S":
            df_data = df_raw[[self.target]]
        if self.scale:
            train_data = df_data[border1s[0] : border2s[0]]
            self.scaler.fit(train_data.values)
            data = self.scaler.transform(df_data.values)
        else:
            data = df_data.values
        df_stamp = df_raw[["date"]][border1:border2]
        df_stamp["date"] = pd.to_datetime(df_stamp.date)
        if self.timeenc == 0:
            df_stamp["month"] = df_stamp.date.apply(lambda row: row.month, 1)
            df_stamp["day"] = df_stamp.date.apply(lambda row: row.day, 1)
            df_stamp["weekday"] = df_stamp.date.apply(lambda row: row.weekday(), 1)
            df_stamp["hour"] = df_stamp.date.apply(lambda row: row.hour, 1)
            data_stamp = df_stamp.drop(["date"], 1).values
        elif self.timeenc == 1:
            data_stamp = time_features(pd.to_datetime(df_stamp["date"].values), freq=self.freq)
            data_stamp = data_stamp.transpose(1, 0)
        self.data_x = data[border1:border2]
        self.data_y = data[border1:border2]
        self.data_stamp = data_stamp

    def __getitem__(self, index):
        if self.return_single_feature == False:
            s_begin = index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end]
            seq_y = self.data_y[r_begin:r_end]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        else:
            original_index = index // self.C
            channel_index = index % self.C
            s_begin = original_index
            s_end = s_begin + self.seq_len
            r_begin = s_end - self.label_len
            r_end = r_begin + self.label_len + self.pred_len
            seq_x = self.data_x[s_begin:s_end, channel_index : channel_index + 1]
            seq_y = self.data_y[r_begin:r_end, channel_index : channel_index + 1]
            seq_x_mark = self.data_stamp[s_begin:s_end]
            seq_y_mark = self.data_stamp[r_begin:r_end]
        return seq_x, seq_y, seq_x_mark, seq_y_mark

    def __len__(self):
        if self.return_single_feature == False:
            return len(self.data_x) - self.seq_len - self.pred_len + 1
        else:
            return (len(self.data_x) - self.seq_len - self.pred_len + 1) * self.C

    def inverse_transform(self, data):
        return self.scaler.inverse_transform(data)

# ===============================================================================================
#                             <<< ASIL HATA DÜZELTMESİ BURADA >>>
# ===============================================================================================
def update_args_from_dataset(args: argparse.Namespace) -> argparse.Namespace:
    # Set data_path, data, enc_in, seq_len
    if args.data_name == "Weather":
        args.data_path = Path(args.root_path, "dataset", "weather", "weather.csv")
        args.data = "custom"
        args.enc_in = 21
    elif args.data_name == "ETTh1":
        args.data_path = Path(args.root_path, "dataset", "ETT-small", "ETTh1.csv")
        args.data = "ETTh1"
        args.enc_in = 7
    elif args.data_name == "ETTh2":
        args.data_path = Path(args.root_path, "dataset", "ETT-small", "ETTh2.csv")
        args.data = "ETTh2"
        args.enc_in = 7
    elif args.data_name == "ETTm1":
        args.data_path = Path(args.root_path, "dataset", "ETT-small", "ETTm1.csv")
        args.data = "ETTm1"
        args.enc_in = 7
    elif args.data_name == "ETTm2":
        args.data_path = Path(args.root_path, "dataset", "ETT-small", "ETTm2.csv")
        args.data = "ETTm2"
        args.enc_in = 7
    elif args.data_name == "ECL":
        args.data_path = Path(args.root_path, "dataset", "electricity", "electricity.csv")
        args.data = "custom"
        args.enc_in = 321
    elif args.data_name == "Traffic":
        args.data_path = Path(args.root_path, "dataset", "traffic", "traffic.csv")
        args.data = "custom"
        args.enc_in = 862
    # Bizim özel veri setimiz için bir kontrol eklemeye gerek yok,
    # çünkü enc_in değeri zaten main.py'dan doğru şekilde geliyor.

    # Set model_id
    # Hatanın olduğu orijinal satır: args.model_id = args.data_path.name.split(".")[0] + "_" + str(args.pred_len)
    # DÜZELTME: args.data_path'in metin (string) olabileceğini kontrol edip Path nesnesine çeviriyoruz.
    if isinstance(args.data_path, str):
        args.data_path = Path(args.data_path)
    args.model_id = args.data_path.name.split(".")[0] + "_" + str(args.pred_len)

    # Set d_model
    if args.LLM == "gpt2":
        args.LLM_path = args.root_path / Path("LLM", "gpt2")
        args.d_model = 768
    elif args.LLM == "llama":
        args.LLM_path = args.root_path / Path("LLM", "llama")
        args.d_model = 4096
    elif args.LLM == "falcon":
        args.LLM_path = args.root_path / Path("LLM", "falcon")
        args.d_model = 4096
    else:
        raise ValueError(f"LLM {args.LLM} not supported")
        
    # dec_in ve c_out değerlerini enc_in'den türetiyoruz.
    args.dec_in = args.enc_in
    args.c_out = args.enc_in

    return args